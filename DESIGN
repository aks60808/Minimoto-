COMP9243 assignment 3
GROUP 22 
Heng-Chuan Lin z5219960
Ting Ting Peng z5250402       

Extra Files in submitted tar
    - aws_config_script: a shell script for configuring client and watchdog remotely via ssh.
    - aws_config_script_service: a shell script for configuring service instance remotely via ssh.

[Minimoto_setup]

    #General steps

        1. configure AWS credential and config in ~/.aws
        2. extract key name from input key file
        3. create SQS
        4. create input and output bucket
        5. create security group
        6. launch instances with t2.large for service, client and watchdog
        7. configure service instance
        8. create service AMI
        9. configure client instance
        10. configure watchdog instance
        11. check status of service AMI

    #Things to know:

        Minimized output files:

            We used python file for all our service, however we only use pure shell aws cli command line rather than boto3.
            Subprocess lib is imported to our program for handling aws cli calls.

        Tags:

            During step 6, We added a tag for all Minimoto-related instances and a tag for only Minimoto service instances.
            The tag for Minimoto service instances can be used as a identifier while monitoring service instances for watchdog.
            And all running instances can be all terminated by another Minimoto tag for Minimoto-related instances during cleanup. 
        
        Configure Priority:
            We first configure Minimoto service instance for operating AMI image creation as soon as possible. During creating the AMI
            image based on Minimoto service instance, Minimoto service instance will be rebooted, so it will take a longer time to be available
            compared to client and watchdog instance.  

        General Configuration for all Minimoto instance:

            All configuration instructions for watchdog and client are in file:aws_config_script.
            All configuration instruction for service are in file:aws_config_script_service
            We scp things are required for running aws cli like credential and config in ~/.aws
            Since we use public ami image Ubuntu 16 from launching page, it is clean image at all.
            We install aws cli 2 for each of them. 

        Configuration of Minimoto service instance:

            We installed imagemagick and libav-tools for operating our transcode service.
            And for further monitoring CPU utilization, sysstat is also installed in service instance.
            Scheduling is also included for crontab to execute Minimoto_service regularly. 
            Service instances will need SQS url and name of buckets during execution.
            so we also scp a json file minimoto_info.json included the above information

        Configuration of Minimoto client instance: 

            client instance will have a json file minimoto_info.json for information of SQS url as well.

        Configuration of Minimoto watchdog instance:   
            watchdog will have key file .pem for further ssh to service instances.
            And a much more detailed json file minimoto_config.json including key name, security group id and Service AMI (launching service instances)
        
        Approximated Setup Time:
            it took ~4 minutes for only launching and configuring instances, however for availability of our service, we will 
            wait until the Service AMI is created and is available for launching new service instance based on this AMI.
            Hence, it usually took overall 6-8 minutes until the Service AMI is ready-to-use. But sometimes it would take close to 10 min when 
            traffic is busy.

[Minimoto_cleanup]

    #General steps

        1. delete buckets 
        2. delete sqs
        3. terminate all minimoto-related instances
        4. delete security group
        5. deregister Service AMI
        6. remove any output file generated by minimoto-related programs

    #Things to know:

        1. All information that minimoto_cleanup need is written by Minimoto_setup in minimoto_config.json.
        2. Before deleting security group, minimoto_cleanup will sleep for 60 sec waiting for terminationg of all instances
        3. Since all command is executed on Subprocess, so program can still be executed to the end with some error happened as long
            as there's no failure occurred in python.

[Minimoto_watchdog]

    #Automatically scaling
        we will find idle running instances first and subtract with the length of SQS.
        if length(SQS) - number_of_idle_instances > 0 then we will scale out by |leng(SQS) - number_of_idle_instances|
        if length(SQS) - number_of_idle_instances < 0 then we will "try to" terminate the instances from idle list
        Before actually terminate it, watchdog will measure its CPU utilization again , to see if that instance had things to do.
        Scaling in will be gradually scaling in. for example, if it suggest that we need to scale in by 4, we will only scale in by 3.
        And it won't to scale-in to 0 -> there always to one active service instance.
    #Forcedly scaling
        scale out is easier since there's no need to measure utilization of any current instances.
            But with limitation of our maximum number of instances, only 7 instances can be functional in the same time.
        scale in need to take consider of which instances to be terminated.
            we will measure the instances to obtain a list of idle instances and then terminate them based on how many we need to.
            if that's no enough, watchdog will sadly terminate some/most of them based on how many instances need to be killed for 
            fulfillment of operation.
    #Status check
        will query cloudwatch via aws cli and get the statistical report of avg. CPU utilization from each running instances.
        Sometimes the report of specific instance hasn't been created so watchdog will output not yet initialized for that instance.
        And the avg. CPU utilization of all running service instances will only take the ones with "figure" for CPU utilization. 

[minimoto_client]

   -- Briefly Introdution
	Program minimoto_client uploads local image files to S3-input-bucket 
	which has been configured by program minimoto_setup. After uploading,
	client sends a unique request to SQS. If no wait flag set, client exits.
	Otherwise, client waits until trandcoding finish.
   
   -- Upload Images
	To avoid previous upload images being overwritten by latter upload, we 
	generate an unique suffix to upload folder for each request. We randomly
	pick up 10 characters from 26 uppercase letters, 26 lowercase letters and
	10 numbers. Then we use AWS CLI "aws s3 ls" to check whether the folder with
	suffix already exists. If not, use this suffix to upload images. Therefore,
	theoretically, our prgram can make sure client upload 62^10 times.
   
   -- Send Request
	After uploading all local images, client sends an unique request/message to 
	SQS which also configured by program minimoto_setup. We use the unique folder
	name as message body.
   
   -- Wait Option
	If the wait flag has beed set, after sending the request, client will rather
	exit but using AWS CLI "aws s3api list-objects" to check whether the output
	mp4 file has been upload to output bucket in a while loop.


[minimoto_service]

   -- Briefly Introduction
	There are serveral things need service to do:
		1. check if exist any other service process
		2. check if any request in SQS
 		3. receive request
		4. doing transcode
		5. check if other instance already complete the same request before upload
		5. delete request, delete local files
   
   -- Check If Other Service Process Exist:
	We use comment 'ps -aux' to fetch all the running processes and grep them with
	'python minimoto_service'. If there are 3 processes relate to 'minimoto_service' (one 
	is minimoto_service process, one is 'cron' and other one is 'grep'), we assume
	there is already have a service process and exit.

   -- Receive Request
	We use AWS CLI 'aws sqs receivce-message' to fetch the head request on SQS.
	At the beginning, we use FIFO SQS to impletement 'extactly one processing'.
	But the question is, other receive-message requests will be blocked until the 
	first request has been delete. When there are 20 requests on the queue with 
	VisibilityTimeout=30, the last request needs to wait at least 10 mins. Now we
	just use standard queue and different instances may receive the same request.
 
	When service request message, if no return, it means no any request need to 
	process and then service quit.
	If any request return, service downloads the images from the path contained in
	message body and applies transcode shell script to these image.
	
	When tanscoding finish,servie check whether the mp4 file existed on output bucket
	If no, service uploads the mp4 file to output bucket and delete the request.
	Service also delete all the local images.
	The initial VisibilityTimeout is 1s.

   -- Delete Request
	When service finishs transcode, it need to delete the request on the SQS because AWS will
	not automatically delete the message. Because the request will be deliver at least once, 
	the request will be deleted by who upload the mp4 file successfully.

   -- Cron
	Service program will be fired by cron every 1 minute.


[Shortcomings] 
    #Standard Queue Delivery at Least Once
        VisibilityTimeout for each request is 1 second. In this way, service instance will not 
        idle or block but waiting for request. It takes into the problem that some instances 
        will do the same job but only one job will be submitted successfully. This strategy better
        ensure the request can be executed but not lost if the instance cras but waste instance 
        resources.  
	
    #Limited Request Number
        Different requests require different suffix. Due to the length of suffix( with 10 characters),
        the design can not process more than 63^10 requests without any deletion. But the number is 
        quite enough for this assignment. 
    #Sometime SCP or SSH will have rare chance to get "lost connection"

        We sometimes will have this connection issue, but with limited time, we could not deal with this.
        One teammate suffer from DNS resolving issue within her computer which make us hard to debug this issue.

    #Trancoding Service consume too much memory:

        While testing images close to 100, we will get our transcoding service killed by OOM Killer.
        Or sometimes watchdog try to run a mpstat command to monitor CPU utilization of Service instances,
        the output will be "-bash: fork: Cannot allocate memory".
        These outcome turn out that we need to restrict resource management for transcoding service.
        However we haven't implemented this since we don't have much time.

    #CPU utilization may not be accurate enough for determination of service productivity
        
        So far we measure our instances only by CPU utilization, but cannot really tell which program consume computing power.
        Might come up with some scenario, the program just hanging there infinitely and doing nothing valuable but watchdog still
        think this instance is busy converting images to mp4.
    
    #No mathematical support of our automatically scaling:
    
        We think there should be some researches of modelling scale. But we don't have any time investigate this.
        Our scaling policy is dumb but fine for small scale but may not be robust under the fact that requests length from SQS
        will fluctuate periodically in reality.

    #Maximum number of Service instances capped to 7

        We have issue with scaling out over 9 (1 client +　1 watchdog + 7 services) total instances.
        we have successfully launched the command and get certain response.
        And also see the new launched instances changing state from pending to running, however after few seconds,
        the state will be changed to shutting-down then terminated.
        We suspect there is some policy limiting running instances while using education account

[Testing]
    we only use over 50 images testing our final system due to time limit.
    we first generate 5 requests from client, and use watchdog forcedly scale to 3.
    1 min after we run watchdog to automatically scale out. 
    after 1 min we forcedly scale to only 2 to crash some operation
    finally we observe the SQS request size is 0 and have 5 .mp4 in our output bucket


[Contribution]
    TING TING : implement client ,service 
    HENG CHUAN : implement setup,cleanup,watchdog and final testing
    We contribute equally.
